### 5.1 向量空間基礎

在這一部分中，我們將討論一些關於向量空間的基本概念，包括線性相關性、基與維數、商空間以及直和分解。這些概念在代數和線性代數中具有基礎性的重要性。

#### 1. 線性相關性

**數學定義：**
- 給定一組向量  $`\{ v_1, v_2, \dots, v_n \}`$ ，如果存在一組不全為零的常數  $`c_1, c_2, \dots, c_n`$ ，使得：

  
```math
c_1 v_1 + c_2 v_2 + \dots + c_n v_n = 0
```

  那麼這組向量稱為**線性相關的**。如果沒有這樣的常數，則稱這組向量為**線性無關的**。

**Python 實現：**

```python
import numpy as np

# 檢查一組向量是否線性相關
def check_linear_dependence(vectors):
    # 建立一個矩陣，每列為一個向量
    matrix = np.array(vectors).T
    rank = np.linalg.matrix_rank(matrix)  # 計算矩陣的秩
    if rank == len(vectors):
        return False  # 向量線性無關
    else:
        return True  # 向量線性相關

# 測試
vectors = [[1, 2], [2, 4], [3, 6]]  # 線性相關
print("Are the vectors linearly dependent?", check_linear_dependence(vectors))

vectors2 = [[1, 2], [2, 3], [3, 5]]  # 線性無關
print("Are the vectors linearly dependent?", check_linear_dependence(vectors2))
```

在此範例中，第一組向量是線性相關的，而第二組向量是線性無關的。

#### 2. 基與維數

**數學定義：**
- 向量空間的一組基是該空間的一組線性無關向量組，且該基的所有線性組合可以表示該空間中的任意向量。
- 向量空間的維數是該空間中基的元素數量。

**Python 實現：**

```python
# 計算向量空間的基和維數
def find_basis_and_dimension(vectors):
    matrix = np.array(vectors).T
    _, s, _ = np.linalg.svd(matrix)  # 使用奇異值分解來檢查線性無關性
    rank = np.sum(s > 1e-10)  # 當奇異值大於某個小閾值時，說明這些向量線性無關
    return rank

# 測試
vectors = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]  # 這是 3 維空間的基
print("Dimension of the vector space:", find_basis_and_dimension(vectors))
```

這段程式計算了向量組的維數，並返回該空間的維數。

#### 3. 商空間

**數學定義：**
- 給定向量空間  $`V`$  和其子空間  $`W`$ ，商空間  $`V/W`$  是將  $`V`$  中的元素模掉  $`W`$  中的元素所構成的集合。即商空間是所有  $`V`$  中的向量相對於  $`W`$  的等價類的集合。

**Python 實現：**

```python
# 計算商空間的元素，這裡假設 V 是 R^3，W 是一條直線
def quotient_space_example():
    V = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # R^3 空間
    W = np.array([[1, 1, 1]])  # 子空間 W: 一條直線
    # 商空間的元素是 V 中的向量與 W 的元素的模
    quotient_elements = V - np.dot(V, W.T)  # 計算每個向量在商空間中的對應
    print("Quotient Space Elements:\n", quotient_elements)

quotient_space_example()
```

此範例中，我們將  $`R^3`$  中的向量模掉一條直線上的向量來構造商空間的元素。

#### 4. 直和分解

**數學定義：**
- 向量空間  $`V`$  可以分解為若干個子空間的直和。即存在子空間  $`V_1, V_2, \dots, V_n`$ ，使得  $`V = V_1 \oplus V_2 \oplus \dots \oplus V_n`$ ，並且每個向量在這些子空間中有唯一的表示。

**Python 實現：**

```python
# 直和分解示例，將向量空間分解為兩個子空間
def direct_sum_decomposition():
    V = np.array([2, 3])  # 向量空間中的一個向量
    V1 = np.array([2, 0])  # 子空間 V1
    V2 = np.array([0, 3])  # 子空間 V2
    
    # 計算 V1 和 V2 之和
    decomposition = V1 + V2  # 這是向量 V 在 V1 和 V2 中的唯一表示
    print("Direct Sum Decomposition:", decomposition)

direct_sum_decomposition()
```

在此範例中，我們將一個向量  $`V = [2, 3]`$  分解為兩個子空間  $`V_1`$  和  $`V_2`$  的和，這樣的分解在數學上稱為直和分解。

---

### 總結

這一章介紹了向量空間的一些基本概念，如線性相關性、基與維數、商空間和直和分解。這些概念在許多數學領域中都是基礎，並且可以通過 Python 實現來加深理解。
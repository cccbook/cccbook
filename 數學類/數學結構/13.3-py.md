### 13.3 信息幾何

信息幾何是一門結合了幾何和統計學的學科，主要研究概率空間的幾何結構及其對應的統計量。常見的概念包括 Fisher 信息矩陣、Kullback-Leibler 散度、熵與多樣性指標等。

---

#### 1. Fisher 信息矩陣

**數學定義**：
Fisher 信息矩陣是統計學中衡量參數估計精度的一個工具。對於一組參數化的概率分佈 \( p(x; \theta) \)，其 Fisher 信息矩陣定義為：

\[
I(\theta) = \mathbb{E}\left[ \left( \frac{\partial}{\partial \theta} \log p(x; \theta) \right)^2 \right]
\]
這裡，\( \mathbb{E} \) 是對隨機變數 \( x \) 的期望操作，\( \theta \) 是模型中的參數。

---

#### Python 實作：
下面的程式計算了基於正態分佈的 Fisher 信息矩陣，其中正態分佈的參數是均值 \( \mu \) 和方差 \( \sigma^2 \)。

```python
import numpy as np
from scipy.stats import norm

# Fisher信息矩陣的計算：對於正態分佈 N(mu, sigma^2)
def fisher_information(mu, sigma):
    # 對數似然函數的導數
    def log_likelihood_derivatives(x, mu, sigma):
        d_mu = (x - mu) / (sigma ** 2)  # 對 mu 的偏導數
        d_sigma = ( (x - mu) ** 2 - sigma ** 2 ) / (sigma ** 3)  # 對 sigma 的偏導數
        return d_mu, d_sigma

    # 隨機生成樣本
    n_samples = 1000
    samples = np.random.normal(mu, sigma, n_samples)
    
    # 計算對數似然的導數
    d_mu, d_sigma = log_likelihood_derivatives(samples, mu, sigma)
    
    # 計算Fisher信息矩陣
    fisher_mu = np.mean(d_mu ** 2)
    fisher_sigma = np.mean(d_sigma ** 2)
    fisher_cross = np.mean(d_mu * d_sigma)
    
    fisher_matrix = np.array([[fisher_mu, fisher_cross], [fisher_cross, fisher_sigma]])
    return fisher_matrix

# 計算並顯示 Fisher 信息矩陣
mu = 0  # 均值
sigma = 1  # 標準差
fisher_matrix = fisher_information(mu, sigma)
print("Fisher Information Matrix:")
print(fisher_matrix)
```

這段程式計算了對於正態分佈，參數 \( \mu \) 和 \( \sigma^2 \) 的 Fisher 信息矩陣。`fisher_information` 函數通過計算對數似然函數對每個參數的導數來估計信息矩陣。

---

#### 2. Kullback-Leibler 散度

**數學定義**：
Kullback-Leibler 散度（KL 散度）是用來衡量兩個概率分佈 \( P \) 和 \( Q \) 之間差異的非對稱度量。它定義為：

\[
D_{KL}(P \parallel Q) = \sum_{x} P(x) \log \frac{P(x)}{Q(x)}
\]
對於連續隨機變數，這個定義改為積分形式。

---

#### Python 實作：
下面的程式演示了如何計算正態分佈的 KL 散度，假設有兩個正態分佈 \( N(\mu_1, \sigma_1^2) \) 和 \( N(\mu_2, \sigma_2^2) \)。

```python
from scipy.stats import norm

def kl_divergence(mu1, sigma1, mu2, sigma2):
    # 兩個正態分佈的KL散度公式
    term1 = np.log(sigma2 / sigma1)
    term2 = (sigma1 ** 2 + (mu1 - mu2) ** 2) / (2 * sigma2 ** 2)
    term3 = -0.5
    return term1 + term2 + term3

# 計算兩個正態分佈之間的KL散度
mu1, sigma1 = 0, 1  # 第一個正態分佈的參數
mu2, sigma2 = 1, 2  # 第二個正態分佈的參數
kl_value = kl_divergence(mu1, sigma1, mu2, sigma2)
print(f"Kullback-Leibler Divergence: {kl_value}")
```

這段程式計算了兩個正態分佈之間的 KL 散度，根據公式計算了該散度的值。

---

#### 3. 熵與多樣性指標

**數學定義**：
熵是衡量隨機變量不確定性的量度。對於離散隨機變量 \( X \)，熵定義為：

\[
H(X) = - \sum_{x} P(x) \log P(x)
\]
而多樣性指標則是用來量化系統中元素多樣性的度量，通常用熵來度量系統的多樣性。

---

#### Python 實作：
下面的程式演示了如何計算離散隨機變量的熵。

```python
def entropy(pmf):
    # 計算離散隨機變量的熵
    return -np.sum(pmf * np.log(pmf))

# 計算簡單的離散分佈的熵
pmf = np.array([0.25, 0.25, 0.25, 0.25])  # 這是一個均勻分佈
entropy_value = entropy(pmf)
print(f"Entropy: {entropy_value}")
```

這段程式計算了均勻分佈的熵。

---

#### 4. 信息幾何與貝葉斯推斷

**數學定義**：
在信息幾何中，貝葉斯推斷是一種基於觀察數據更新信念的過程。根據貝葉斯定理，更新後的概率分佈 \( p(\theta | x) \) 是根據先驗分佈 \( p(\theta) \) 和似然函數 \( p(x|\theta) \) 來計算的：
\[
p(\theta | x) = \frac{p(x | \theta) p(\theta)}{p(x)}
\]
貝葉斯推斷可通過信息幾何中的方法來表示，並使用 Fisher 信息矩陣來描述參數的不確定性。

---

#### Python 實作：
下面的程式演示了如何用貝葉斯推斷來更新正態分佈的參數，並計算後驗分佈。

```python
from scipy.stats import norm

# 計算後驗分佈
def bayesian_inference(mu_prior, sigma_prior, x_data, likelihood_func):
    n = len(x_data)
    # 根據貝葉斯定理更新參數
    mu_likelihood = np.mean(x_data)
    sigma_likelihood = np.std(x_data)
    
    # 使用貝葉斯公式更新先驗
    mu_posterior = (mu_prior / sigma_prior**2 + mu_likelihood * n / sigma_likelihood**2) / (1 / sigma_prior**2 + n / sigma_likelihood**2)
    sigma_posterior = np.sqrt(1 / (1 / sigma_prior**2 + n / sigma_likelihood**2))
    
    return mu_posterior, sigma_posterior

# 模擬數據
x_data = np.random.normal(1, 2, 100)

# 初始先驗
mu_prior = 0
sigma_prior = 1

# 計算後驗分佈的參數
mu_posterior, sigma_posterior = bayesian_inference(mu_prior, sigma_prior, x_data, norm.pdf)
print(f"Posterior Mean: {mu_posterior}, Posterior Standard Deviation: {sigma_posterior}")
```

這段程式使用貝葉斯推斷更新正態分佈的均值和標準差，並計算後驗分佈的參數。

---

### 小結

在這一節中，我們介紹了信息幾何的基本概念，包括 Fisher 信息矩陣、Kullback-Leibler 散度、熵與多樣性指標，以及信息幾何在貝葉斯推斷中的應用。通過使用 Python 實作這些概念，我們展示了如何計算和應用這些工具來分析概率分佈和隨機過程的結構。
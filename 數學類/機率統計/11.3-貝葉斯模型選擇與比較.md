### 11.3 貝葉斯模型選擇與比較

貝葉斯模型選擇與比較是一個重要的課題，特別是在多個候選模型之間進行選擇時。貝葉斯方法提供了一種統一的框架來處理模型選擇問題，通過比較不同模型的後驗分布或後驗預測誤差來選擇最佳模型。這樣的比較可以幫助我們理解不同模型的相對優勢，並根據數據進行合理的選擇。

#### 11.3.1 貝葉斯因子（Bayes Factor）

貝葉斯因子是一種常用於模型選擇的工具。它用來比較兩個模型 \( M_1 \) 和 \( M_2 \) 的相對優劣，並且量化哪個模型更適合數據。貝葉斯因子的計算公式為：

\[
BF_{12} = \frac{P(\mathbf{X} | M_1)}{P(\mathbf{X} | M_2)}
\]

其中：
- \( P(\mathbf{X} | M_1) \) 是模型 \( M_1 \) 在觀察數據 \( \mathbf{X} \) 下的邊際似然（即模型 \( M_1 \) 的證據）。
- \( P(\mathbf{X} | M_2) \) 是模型 \( M_2 \) 在觀察數據 \( \mathbf{X} \) 下的邊際似然。

如果 \( BF_{12} > 1 \)，則模型 \( M_1 \) 比 \( M_2 \) 更適合數據；如果 \( BF_{12} < 1 \)，則模型 \( M_2 \) 更適合數據。貝葉斯因子不僅考慮了模型的擬合程度，還考慮了模型的複雜性。它是一種平衡擬合和簡單性的指標。

#### 11.3.2 邊際似然（Marginal Likelihood）

邊際似然是貝葉斯模型選擇中的另一個關鍵概念，它是給定觀察數據 \( \mathbf{X} \) 下的模型的證據，計算公式為：

\[
P(\mathbf{X} | M) = \int P(\mathbf{X} | \theta, M) P(\theta | M) d\theta
\]

其中：
- \( P(\mathbf{X} | \theta, M) \) 是在參數 \( \theta \) 下的似然函數，描述了觀察數據的生成過程。
- \( P(\theta | M) \) 是模型 \( M \) 的先驗分布，表示對參數 \( \theta \) 的先驗信念。
- 積分操作是對所有可能的參數值 \( \theta \) 進行積分，得出模型 \( M \) 的邊際似然。

邊際似然提供了模型對數據的擬合程度。較高的邊際似然表示該模型能夠更好地解釋數據。在貝葉斯模型選擇中，通常會比較不同模型的邊際似然，選擇邊際似然最大的模型。

#### 11.3.3 貝葉斯信息準則（BIC）與赤池信息準則（AIC）

雖然 BIC 和 AIC 最初是頻率學派的模型選擇方法，但它們也可以在貝葉斯框架中進行解釋，並常用於模型選擇的比較。這些準則衡量模型擬合程度和複雜性之間的平衡：

- **貝葉斯信息準則（BIC）**：
  
  \[
  BIC = -2 \ln L(\hat{\theta}) + k \ln n
  \]
  其中，\( L(\hat{\theta}) \) 是模型的最大似然估計，\( k \) 是模型中的參數數量，\( n \) 是樣本數量。較小的 BIC 值表示模型較好。

- **赤池信息準則（AIC）**：
  
  \[
  AIC = -2 \ln L(\hat{\theta}) + 2k
  \]
  其中，\( L(\hat{\theta}) \) 是最大似然估計，\( k \) 是參數數量。AIC 也試圖平衡模型擬合程度與複雜性，較小的 AIC 值表示較好的模型。

這些準則在貝葉斯推論中的意義類似於貝葉斯因子，但通常 BIC 和 AIC 是基於頻率學派的最大似然估計，而不是基於邊際似然。

#### 11.3.4 後驗預測檢驗

後驗預測檢驗（Posterior Predictive Checking）是一種利用後驗分布對模型進行驗證的方法。在這種方法中，我們基於後驗分布生成預測數據，並將其與實際觀察數據進行比較。如果模型能夠生成與實際數據相似的預測數據，則說明該模型對數據的擬合程度較好。

具體過程如下：
1. 根據後驗分布樣本 \( \theta^{(s)} \)，生成預測數據 \( \mathbf{X}^{(s)} \)。
2. 比較生成的預測數據與實際數據，評估模型的擬合效果。
3. 若預測數據與實際數據的差異較大，則可能表明該模型不適合，反之則說明模型較為合理。

#### 11.3.5 模型平均（Model Averaging）

貝葉斯模型選擇不僅僅是選擇一個最好的模型，還可以進行模型平均（Model Averaging）。這是一種方法，通過將多個模型的後驗預測結合起來，得到一個綜合預測結果。模型平均的優勢在於它能夠減少單一模型選擇錯誤的風險，並且通常能夠提供更穩健的預測。

模型平均的基本思想是根據每個模型的後驗概率加權平均，計算加權後的預測：

\[
\hat{y}_{\text{avg}} = \sum_{i=1}^{k} P(M_i | \mathbf{X}) \hat{y}_{i}
\]

其中：
- \( P(M_i | \mathbf{X}) \) 是模型 \( M_i \) 的後驗概率，表示模型 \( M_i \) 在觀察數據下的相對可信度。
- \( \hat{y}_i \) 是來自模型 \( M_i \) 的預測。

#### 11.3.6 小結

貝葉斯模型選擇與比較是一個重要的課題，貝葉斯因子、邊際似然、AIC、BIC 和後驗預測檢驗等方法為我們提供了多種衡量模型好壞的工具。通過這些方法，我們可以根據數據選擇最適合的模型，並且在多個模型之間進行比較。貝葉斯模型平均方法進一步增強了預測的穩健性，為許多應用場景提供了靈活的解決方案。
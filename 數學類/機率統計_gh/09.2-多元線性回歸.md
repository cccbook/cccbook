### 9.2 多元線性回歸

多元線性回歸（Multiple Linear Regression）是回歸分析中的一種方法，用於研究一個因變數（響應變數）與兩個或更多自變數（解釋變數）之間的線性關係。這是一個廣泛應用於多種領域的統計工具，如經濟學、醫學、社會科學、工程學等，用來描述複雜的現象。

#### 9.2.1 模型建立

多元線性回歸的基本模型假設因變數  $`y`$  與多個自變數  $`x_1, x_2, ..., x_p`$  之間存在線性關係，這個關係可以表示為：

```math
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p + \epsilon
```

其中：
-  $`y`$  是因變數（響應變數），是要預測或解釋的變量。
-  $`x_1, x_2, ..., x_p`$  是自變數（解釋變數），用來解釋因變數的變化。
-  $`\beta_0`$  是截距（intercept），表示當所有自變數  $`x_1, x_2, ..., x_p`$  都為 0 時，因變數的預測值。
-  $`\beta_1, \beta_2, ..., \beta_p`$  是回歸係數（regression coefficients），表示每個自變數對因變數的影響程度。
-  $`\epsilon`$  是誤差項（error term），表示模型無法解釋的隨機變量或測量誤差。

#### 9.2.2 最小二乘法估計

與一元線性回歸一樣，多元線性回歸的參數  $`\beta_0, \beta_1, ..., \beta_p`$  也可以通過最小二乘法來估計。最小二乘法的目標是最小化所有觀察值的預測誤差的平方和，具體公式為：

```math
S(\beta_0, \beta_1, ..., \beta_p) = \sum_{i=1}^n (y_i - (\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + ... + \beta_p x_{ip}))^2
```

其中， $`y_i`$  是第  $`i`$  個觀察值的因變數， $`x_{i1}, x_{i2}, ..., x_{ip}`$  是相應的自變數。

通過對這個目標函數對  $`\beta_0, \beta_1, ..., \beta_p`$  求偏導數並令其為零，可以得到最小化誤差平方和的估計參數。

#### 9.2.3 估計參數

多元線性回歸的回歸係數  $`\beta_0, \beta_1, ..., \beta_p`$  的估計值可以通過矩陣運算得到。設  $`\mathbf{X}`$  為包含自變數的設計矩陣， $`\mathbf{y}`$  為因變數的向量，回歸係數  $`\boldsymbol{\beta}`$  的估計值  $`\hat{\boldsymbol{\beta}}`$  可以使用以下公式計算：

```math
\hat{\boldsymbol{\beta}} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y}
```

其中， $`\mathbf{X}^T`$  是設計矩陣  $`\mathbf{X}`$  的轉置， $`(\mathbf{X}^T \mathbf{X})^{-1}`$  是  $`\mathbf{X}^T \mathbf{X}`$  的逆矩陣。這樣，我們就可以計算出回歸方程：

```math
\hat{y} = \hat{\beta_0} + \hat{\beta_1} x_1 + \hat{\beta_2} x_2 + ... + \hat{\beta_p} x_p
```

其中  $`\hat{y}`$  是對因變數  $`y`$  的預測值。

#### 9.2.4 假設檢定

與一元回歸一樣，在多元線性回歸中，我們通常會對回歸係數進行假設檢定，以確定每個自變數是否顯著地影響因變數。假設檢定的零假設通常是  $`H_0: \beta_j = 0`$ ，即自變數  $`x_j`$  對因變數  $`y`$  沒有顯著影響。

t 檢定統計量可以計算為：

```math
t_j = \frac{\hat{\beta_j}}{SE(\hat{\beta_j})}
```

其中， $`\hat{\beta_j}`$  是回歸係數的估計值， $`SE(\hat{\beta_j})`$  是該估計值的標準誤差。根據自由度  $`n - p - 1`$  查找對應的 t 值，進行假設檢定。

#### 9.2.5 決定係數（ $`R^2`$ ）

決定係數  $`R^2`$  用來衡量模型的擬合度，即自變數是否能解釋因變數的變異。其計算公式為：

```math
R^2 = 1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n (y_i - \bar{y})^2}
```

其中， $`\hat{y}_i`$  是第  $`i`$  個觀察值的預測值， $`\bar{y}`$  是因變數的樣本均值。 $`R^2`$  的範圍從 0 到 1，越接近 1 表示模型的擬合度越高。

#### 9.2.6 殘差分析

殘差分析是回歸模型評估中的重要步驟，用來檢驗模型假設的有效性。殘差  $`e_i`$  是觀察值與預測值之間的差異，即：

```math
e_i = y_i - \hat{y}_i
```

殘差分析可以用來檢查：
- 殘差是否隨機分佈，沒有明顯的模式。
- 殘差是否呈現正態分佈。
- 殘差的變異是否隨自變數的變化而改變。

#### 9.2.7 多重共線性

多重共線性是指在多元線性回歸中，兩個或更多自變數之間存在強烈的線性關係，這會使得回歸係數的估計變得不穩定，進而影響模型的解釋力和預測能力。常見的檢測方法包括計算方差膨脹因子（VIF），如果 VIF 值較大，表示該變數與其他變數之間可能存在多重共線性。

#### 9.2.8 小結

多元線性回歸是一種研究多個自變數與一個因變數之間線性關係的重要工具。通過最小二乘法估計回歸係數，並利用模型進行預測和解釋。假設檢定、殘差分析和決定係數是評估模型有效性的重要手段。在應用中需要注意多重共線性問題，並進行必要的處理。
### 9.1 一元線性回歸

一元線性回歸（Simple Linear Regression）是回歸分析中最基礎的一種方法，它用於研究一個自變數（或稱為解釋變數）與一個因變數（或稱為響應變數）之間的線性關係。這種方法假設因變數與自變數之間的關係可以用一條直線來表示。

#### 9.1.1 模型建立

一元線性回歸模型假設因變數  $`y`$  與自變數  $`x`$  之間的關係如下：

```math
y = \beta_0 + \beta_1 x + \epsilon
```

其中：
-  $`y`$  是因變數（響應變數），表示要預測或解釋的數值。
-  $`x`$  是自變數（解釋變數），用來解釋或預測  $`y`$  的數值。
-  $`\beta_0`$  是截距（intercept），即當  $`x = 0`$  時  $`y`$  的預測值。
-  $`\beta_1`$  是斜率（slope），表示自變數  $`x`$  每增加一單位時，因變數  $`y`$  預期變化的量。
-  $`\epsilon`$  是誤差項（error term），表示所有無法由  $`x`$  解釋的隨機變量或測量誤差。

#### 9.1.2 最小二乘法

為了估計回歸模型中的未知參數  $`\beta_0`$  和  $`\beta_1`$ ，通常使用最小二乘法（Least Squares Method）。最小二乘法的目標是最小化預測值與實際觀察值之間的差異，即最小化以下目標函數（殘差平方和）：

```math
S(\beta_0, \beta_1) = \sum_{i=1}^n (y_i - (\beta_0 + \beta_1 x_i))^2
```

其中， $`y_i`$  是第  $`i`$  個觀察值的因變數， $`x_i`$  是相應的自變數， $`n`$  是樣本數量。通過對這個目標函數對  $`\beta_0`$  和  $`\beta_1`$  求偏導數並令其為零，可以得到最小化該函數的參數估計值。

#### 9.1.3 估計參數

通過最小二乘法，我們可以計算出  $`\beta_0`$  和  $`\beta_1`$  的估計值：
- 斜率  $`\hat{\beta_1}`$  的估計值為：
  
```math
\hat{\beta_1} = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2}
```

  其中， $`\bar{x}`$  是自變數的樣本均值， $`\bar{y}`$  是因變數的樣本均值。
  
- 截距  $`\hat{\beta_0}`$  的估計值為：
  
```math
\hat{\beta_0} = \bar{y} - \hat{\beta_1} \bar{x}
```

  
這樣就可以得到回歸方程：

```math
\hat{y} = \hat{\beta_0} + \hat{\beta_1} x
```

其中  $`\hat{y}`$  是對因變數  $`y`$  的預測值。

#### 9.1.4 預測與解釋

有了回歸方程後，我們可以用自變數  $`x`$  的值來預測因變數  $`y`$  的值。預測公式為：

```math
\hat{y} = \hat{\beta_0} + \hat{\beta_1} x
```

這種預測在數據的範圍內是有效的，並且我們假設模型中包含的線性關係能夠準確地反映現實情況。

此外，斜率  $`\hat{\beta_1}`$  的估計值提供了  $`x`$  和  $`y`$  之間關係的度量。當  $`\hat{\beta_1} > 0`$  時，表示  $`x`$  與  $`y`$  之間存在正相關；當  $`\hat{\beta_1} < 0`$  時，表示存在負相關；如果  $`\hat{\beta_1} = 0`$ ，則表示  $`x`$  和  $`y`$  之間沒有線性關聯。

#### 9.1.5 殘差分析

殘差是觀察值與預測值之間的差異，即：

```math
e_i = y_i - \hat{y}_i
```

其中， $`e_i`$  是第  $`i`$  個觀察值的殘差， $`\hat{y}_i`$  是對應的預測值。殘差分析是回歸分析中的重要步驟，用來檢驗回歸模型的假設是否成立。主要分析項目包括：
- 殘差是否隨機分佈，沒有明顯的模式。
- 殘差是否呈現正態分佈。
- 殘差的變異是否隨自變數的變化而改變。

#### 9.1.6 假設檢定

回歸模型的參數可以進行假設檢定來檢驗其顯著性。最常見的檢定方法是 t 檢定，用來檢驗斜率  $`\beta_1`$  是否顯著不為零。零假設是  $`H_0: \beta_1 = 0`$ ，即自變數與因變數之間沒有線性關係。

t 檢定統計量計算公式為：

```math
t = \frac{\hat{\beta_1}}{SE(\hat{\beta_1})}
```

其中， $`SE(\hat{\beta_1})`$  是  $`\hat{\beta_1}`$  的標準誤差。根據自由度  $`n-2`$  查找對應的 t 值，進行假設檢定。

#### 9.1.7 決定係數（ $`R^2`$ ）

決定係數  $`R^2`$  是回歸模型擬合度的衡量指標，表示自變數解釋因變數變異的比例。其計算公式為：

```math
R^2 = 1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n (y_i - \bar{y})^2}
```

其中，分子是殘差平方和，分母是總平方和。 $`R^2`$  的值範圍從 0 到 1，越接近 1 表示回歸模型對數據的擬合程度越高。

#### 9.1.8 小結

一元線性回歸是回歸分析中最基礎的方法，用於建立自變數與因變數之間的線性關係。通過最小二乘法估計模型參數，並利用模型進行預測和解釋。殘差分析、假設檢定和  $`R^2`$  是評估模型有效性的重要工具。這些技術廣泛應用於各種領域，如經濟學、社會科學、工程學等，幫助研究人員理解變數之間的關聯，並做出預測。
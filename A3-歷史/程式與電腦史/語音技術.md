### 語音技術發展年表

#### 1950s - 1960s: 語音識別的早期研究與實驗

- **1950年代**：語音識別技術的初步研究開始，主要由學術界進行，早期的目標是識別單個語音命令。
  - **1952年**：IBM推出首個語音識別系統**"Shoebox"**，能識別十個數字的語音輸入，是語音識別歷史中的一個里程碑。
- **1950年代中期**：美國國防部資助語音識別研究，並提出“語音模式”概念，開始嘗試通過機械裝置來模擬和識別語音。

#### 1970s: 基本語音識別與模型的發展

- **1971年**：**Harvard的教授**推出**"Audrey"**系統，能夠識別數字語音，這是語音識別的一個重要進展。
- **1976年**：**連續語音識別**的概念開始出現，研究者開始關注如何處理連續的語音信號，而不僅僅是單個詞語或數字。

#### 1980s: 隱馬可夫模型（HMM）與語音識別的進步

- **1980年代**：**隱馬可夫模型**（HMM）成為語音識別領域的重要理論基礎，這一模型可以有效處理語音信號中的時間依賴性，並成為後來多數語音識別系統的核心。
- **1987年**：**Dragon Systems**發展出首個商業化語音識別系統，能夠識別50個單詞並轉換為文字。
- **1989年**：**語音識別研究進入商業化階段**，例如**Dragon NaturallySpeaking**，它開始能夠支持語音轉文字的基本功能。

#### 1990s: 商業化與自然語言處理的結合

- **1990年**：IBM推出了**"ViaVoice"**語音識別系統，這是一款基於PC的商業語音識別產品，進一步推動了語音識別技術的商業應用。
- **1990年代中期**：語音識別技術與自然語言處理（NLP）結合，開始發展出更為複雜的語音交互系統，如語音輸入法、語音助手等。
- **1997年**：**Microsoft Speech SDK**推出，成為PC上語音識別的主要工具，並支持多語言的語音識別。

#### 2000s: 自然語音交互與大規模語音數據的應用

- **2000年代初期**：**Google**、**Microsoft**等大公司開始將語音識別技術應用於搜索引擎和個人助手中，開啟了語音識別在互聯網和日常生活中的應用。
- **2001年**：**Speech-to-Text**技術（語音轉文字）開始得到廣泛應用，並進一步推動了語音識別技術的商業化。
- **2006年**：**Google語音搜索**推出，為語音識別提供了更大規模的實際應用場景，並開始支持多語言語音識別。
- **2009年**：**Apple推出Siri**，一個基於語音識別的虛擬助手，這標誌著智能手機領域語音交互的普及。

#### 2010s: 深度學習與語音識別革命

- **2011年**：**Google**推出了基於深度學習的語音識別系統，顯著提升了語音識別的準確性，這一時期深度神經網絡（DNN）開始廣泛應用於語音識別技術。
- **2012年**：**DeepSpeech**項目由**Mozilla**開發，基於深度神經網絡的開放源代碼語音識別系統，推動了語音識別技術的開源和共享。
- **2014年**：**Google Now**和**Apple Siri**等語音助手開始進行實時語音識別，並能進行更複雜的語音交互和命令解析。
- **2016年**：**Google Assistant**正式推出，支持多輪對話和語音識別的強大功能，開始廣泛應用於智能家居和物聯網設備中。

#### 2020s: 多語言語音識別與生成

- **2020年**：基於**Transformer**架構的語音識別技術崛起，像是**wav2vec 2.0**等模型進一步提升了語音識別的準確性，並支持語音的端到端學習。
- **2021年**：**OpenAI**推出**Whisper**，一個基於深度學習的語音識別系統，支持多語言和強大的噪音抗性，提升了在現實環境中的應用能力。
- **2022年**：語音生成技術，如**TTS（Text-to-Speech）**和**Voice Cloning**，開始能夠生成更自然、更具情感的語音，這些技術應用於虛擬助手、語音導航和娛樂等領域。

#### 小結

語音技術的發展歷程反映了計算機科學、信號處理、語音學及深度學習技術的共同進步。從早期的單一數字識別到今天的語音助手和多語言語音識別系統，語音技術不僅在精度和速度上取得了長足進步，還擴展到更複雜的語音交互和生成領域，推動了智能家居、人工智能助手、醫療、交通等領域的創新和發展。
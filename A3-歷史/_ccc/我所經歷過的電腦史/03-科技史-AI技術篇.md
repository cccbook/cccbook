# 我所經歷過的電腦科技史 -- (2)  AI技術篇

如果你出生在明治維新時期，和坂本龍馬、福澤諭吉等人同時代

那麼、你可能會看到

高高在上，傳承數百年的幕府

在美國黑船要求靠港補給，開港通商時，驚慌失措的樣子

...

為甚麼呢？

...

因為日本的船，是帆船，沒有風就不會動

...

但是馬修培里率領的黑船艦隊，沒有風，還是可以逆流而上

...

然後你會突然意識到，雙方實力的差距

...

於是，你突然發現，在美國面前，幕府不堪一擊 ...

...

那些高高在上的高級武士，在黑船之前，毫無招架之力

就算你把劍術練得再好

難道你可以學魯夫那樣

告訴索龍說

把那顆月亮 (或那艘船) 給我砍了嗎？

...

...

...

疑

...

我們標題不是要講 AI 的科技史嗎？

為甚麼講到明治維新、魯夫和索龍 ...

...

沒錯

如果你有在關注人工智慧的 AI 技術

你這幾年所經歷的

差不多就是明治維新時期日本人所經歷的

也就是福澤諭吉所說的《一生二世》

...

一輩子經歷兩個截然不同的世界

...

在明治維新之前

日本基本上就是古早的農業社會

...

在明治維新之後

日本已然成為科技與軍事強國

...

這就是福澤諭吉會發出《一生二世》感嘆的原因

...

2022 年

ChatGPT 出現之前

我還在 AI 的農業時代

當我看到 ChatGPT 

那個驚訝應該不亞於坂本龍馬看到黑船

雖然 ChatGPT 背後的相關技術

我很多都有接觸

但是當成品被做出來，活生生地擺在那邊

我知道

黑船入港了

...

我不能拿著刀子，去砍那艘船

而是應該開始，努力理解那艘船背後的動力，也就是蒸汽引擎 (還有那些歐美國家的社會體制)

...

在 AI 的農業時期

我們很早就想做出像 ChatGPT 一樣，甚至是更好的交談程式

但是，沒有人做得到

雖然

圖靈在 1953 年就寫出了《圖靈測試》那篇《思想實驗》論文

假想有一個聊天程式，可以模仿人類去聊天

然後找一些人來做實驗

但是不告訴他們聊天的對象到底是真人還是程式

最後再問這些人

你認為剛剛聊天的對象是真人還是程式

...

如果這些人無法有效判斷

或者說根本就是亂猜

經常把真人當程式，把程式當真人

那麼我們就說這個聊天程式，通過了圖靈測試

...

雖然圖靈可以想出測試程式是否有智慧的方法

但是卻沒辦法做出有智慧的程式

而且很年輕就因為同性戀被判《閹割去勢化學療法》

很可能是因此而服下有氰化物的蘋果自殺了

而圖靈在二次大戰密碼破解上的貢獻

直到死後五十年才逐漸被人了解

因為英國這方面的檔案一直是保密的

...

不過，雖然圖靈沒做出聊天程式

但是其他人會做

...

1964 年，馬省理工 MIT 的 Joseph Weizenbaum ，做了一個很簡單的聊天小程式

但是卻騙過了很多人

讓人們以為他們正在和其他人聊天

1966 年 Joseph Weizenbaum 寫了一篇論文，投稿到 Computational Linguisitcs (Communications of ACM) 期刊上

> [ELIZA – a computer program for the study of natural language communication between man and machine]

...

問題是，Eliza 算是通過了圖靈測試嗎？

...
...
...


如果單純以結果論

那麼我們可以說 Eliza 成功的欺騙過一部分人，所以算是部分通過圖靈測試 

...


但是如果要說 Eliza 有智慧

那麼我想應該很少《程式人》會同意

...

因為只要你看了 Eliza 的程式或規則，那麼你對這個程式的幻想就蕩然無存了

以下是我仿製的中文版 Eliza 的一些規則

```
var qaList = [
{ Q:"謝謝", A:"不客氣!"},
{ Q:"對不起 | 抱歉 | 不好意思", A:"別說抱歉 !|別客氣，儘管說 !"},
{ Q:"可否 | 可不可以", A:"你確定想*?"},
{ Q:"我想", A:"你為何想*?"},
{ Q:"我要", A:"你為何要*?"},
{ Q:"你是", A:"你認為我是*?"},
{ Q:"認為 | 以為", A:"為何說*?"},
{ Q:"感覺", A:"常有這種感覺嗎?"},
{ Q:"為何不", A:"你希望我*!"},
{ Q:"是否", A:"為何想知道是否*?"},
{ Q:"不能", A:"為何不能*?|你試過了嗎?|或許你現在能*了呢?"},
{ Q:"我是", A:"你好，久仰久仰!"},
{ Q:"甚麼 | 什麼 | 何時 | 誰 | 哪裡 | 如何 | 為何 | 因何", A:"為何這樣問?|為何你對這問題有興趣?|你認為答案是甚麼呢?|你認為如何呢?|你常問這類問題嗎?|這真的是你想知道的嗎?|為何不問問別人?|你曾有過類似的問題嗎?|你問這問題的原因是甚麼呢?"},
{ Q:"原因", A:"這是真正的原因嗎?|還有其他原因嗎?"}, 
{ Q:"理由", A:"這說明了甚麼呢?|還有其他理由嗎?"},
{ Q:"你好 | 嗨 | 您好", A:"你好，有甚麼問題嗎?"},
{ Q:"或許", A:"你好像不太確定?"},
{ Q:"不曉得 | 不知道", A:"為何不知道?|在想想看，有沒有甚麼可能性?"},
{ Q:"不想 | 不希望", A:"有沒有甚麼辦法呢?|為何不想*呢?|那你希望怎樣呢?"}, 
{ Q:"想 | 希望", A:"為何想*呢?|真的想*?|那就去做阿?為何不呢?"},
{ Q:"不", A:"為何不*?|所以你不*?"},
{ Q:"請", A:"我該如何*呢?|你想要我*嗎?"},
{ Q:"你", A:"你真的是在說我嗎?|別說我了，談談你吧!|為何這麼關心我*?|不要再說我了，談談你吧!|你自己*"},
{ Q:"總是 | 常常", A:"能不能具體說明呢?|何時?"},
{ Q:"像", A:"有多像?|哪裡像?"},
{ Q:"對", A:"你確定嗎?|我了解!"},
{ Q:"朋友", A:"多告訴我一些有關他的事吧!|你認識他多久了呢?"},
{ Q:"電腦", A:"你說的電腦是指我嗎?"}, 
{ Q:"難過", A:"別想它了|別難過|別想那麼多了|事情總是會解決的"},
{ Q:"高興", A:"不錯ㄚ|太棒了|這樣很好ㄚ"},
{ Q:"是阿|是的", A:"甚麼事呢?|我可以幫助你嗎?|我希望我能幫得上忙!"},
{ Q:"", A:"我了解|我能理解|還有問題嗎 ?|請繼續說下去|可以說的更詳細一點嗎?|這樣喔! 我知道!|然後呢? 發生甚麼事?|再來呢? 可以多說一些嗎|接下來呢? |可以多告訴我一些嗎?|多談談有關你的事，好嗎?|想多聊一聊嗎|可否多告訴我一些呢?"}
];  
```

會寫程式的人，可以很容易的想到，整個程式就是

1. 對 Q 進行字串比對
2. 比對到後用 A 當樣板去回答 (偶爾會加上前後文插入)

就這樣，沒了

所以你會說這個程式有智慧嗎？

...

但是，你能說這個程式沒智慧嗎？

他明明成功的欺騙過很多人，通過了部分的圖靈測試 ...

...

當 iPhone 的 Siri 出來之後，我並沒有太多驚訝

因為我知道， Siri 其實只是進階版的 Eliza 而已。

...

但是當 ChatGPT 出來，那就不一樣了

我知道這和 Eliza 沒有半毛錢關係

Eliza 完全不可能做到 ChatGPT 的那些事情

然後我想到了 Karpathy 的一篇文章

> [The Unreasonable Effectiveness of Recurrent Neural Networks]

我知道 ChatGPT 使用的是神經網路，但應該不是 Recurrent Neural Networks (RNN)

而是 Google 提出的 Transformer

因為 Transformer 的效果比 RNN 好得多，而且當時的主流 Transformer 改良技術是 Google 提出 BERT

於是我開始去看 Transformer 的原始經典論文

> [Attention is all you need]

但慚愧的是，我看得似懂非懂

雖然已經受過博士生的訓練，但是我的學術能力仍然相當薄弱

我仍然是個程式人，而非學術研究者

所以我開始找 github 上的程式

還好我在 2022 年的 AI 課程已經開始改用 Python 

而不是很多年前用的 JavaScript

Python 在 github 上的 AI 資源相對多很多

畢竟 Python 是 AI 語言的王者

而且我經常追蹤 Karpathy 的 github 

發現他有很多寫得很清楚的 AI 專案

如果你想了解神經網路與深度學習

第一個要了解的是《梯度下降法》

然後要知道《反傳遞演算法》如何用來做自動微分，加速梯度的計算

你可以看 Kaparthy 的 [micrograd] 專案了解如何寫一個自動微分引擎

...

當我看過 Karpathy 那篇 [The Unreasonable Effectiveness of Recurrent Neural Networks] 之後

我知道循環神經網路和 Transformer 都能學會文章的自動寫作

但是我不知道該怎麼實作 Transformer

後來又是 Karpathy 解救了我

Karpathy 離開了特斯拉之後

寫了一個 minGPT 的程式

我把 minGPT 用 git clone 之後，還對程式重要部份加上註解，並寫了一整本的電子書

> GPT 背後的數學與程式

放在 py2gpt 這個專案裡面

我開始慢慢能理解 GPT 是怎麼做出來的了

但是距離 ChatGPT 還有一段不小的距離

我繼續看 Karpathy 的一些網路資源

看到他在微軟的 [State of GPT | BRK216HFS] 這場演講後

有點模糊的知道從 GPT2 到 ChatGPT 之間，到底有哪些東西，但不是很清楚

後來，臉書出了開放原始碼版本的 ChatGPT 稱為 LLAMA 與 LLAMA2，而且 Karpathy 用 C 語言寫了一個 [llama2.c]

我下載了之後可以執行

目前還在仔細研究 [llama2.c] 的模型中

之後應該也會寫教材來解說 llama2 的模型與原理

(另外也有人將其改寫為 C++ 版的 [llama2.cpp] ，熟悉 C++ 的人可以參考)

這樣

我終於能看到黑船背後的動力引擎了

雖然，我的 GPU 動力不足，還練不出 OpenAI 的那種 GPT

但是差距也就沒有那麼大了 ...

黑船，終究還是一艘船

我們不能用刀去砍它

但是我們可以了解它，甚至在未來超越它

不過，當我們在追趕的同時，美國還持續在進步著

這幾天 OpenAI 釋出的 [Sora] 這個 text2video 展示

讓我們可以直接用劇本產生影片

背後的機制雖然是我們已經知道的 diffusion model 

和 DALLE ， Midjourney 所用的類似

但在影片上的效果，卻超越之前的 Pika 這類程式很多

看來 OpenAI 的黑船，逐漸形成了一支艦隊

還有待我們去研究它！

如果你對這些 AI 主題有興趣

或許不用急著看程式

先去玩玩網路上一些展示

像是 

1. ChatGPT (聊天，問答，任何問題都可以，但不能有道德疑慮)
2. Bing Image Creator (可以告訴他要畫甚麼圖，它就會幫你畫)
3. Suno (自動作曲，人人都是《周杰倫+方文山》)
4. 看看 Sora 產生的影片 (很快可能你一個人用 Sora 就能拍出好萊塢等級的電影了)

或許，我這一代超越不了

但是將這些技術呈現出來，讓學生了解

或許我的學生們，或者看到這篇文章的新一代程式人，會因此而超越 OpenAI 也說不定 ...

## 參考文獻

[ELIZA]:https://en.wikipedia.org/wiki/ELIZA

[ELIZA – a computer program for the study of natural language communication between man and machine]:https://cse.buffalo.edu/~rapaport/572/S02/weizenbaum.eliza.1966.pdf

[Attention is all you need]:https://arxiv.org/abs/1706.03762

[State of GPT | BRK216HFS]:https://www.youtube.com/watch?v=bZQun8Y4L2A

[micrograd]:https://github.com/karpathy/micrograd

[llama2.c]:https://github.com/karpathy/llama2.c

[llama2.cpp]:https://github.com/leloykun/llama2.cpp
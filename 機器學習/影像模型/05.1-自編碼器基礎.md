#### 第五章：變分自編碼器(VAE)

##### 5.1 自編碼器基礎

自編碼器（Autoencoder，AE）是一種無監督學習模型，用於將輸入數據壓縮成更小的隱含表示並從中重建原始數據。其主要由兩個部分組成：編碼器（Encoder）和解碼器（Decoder）。自編碼器的目標是學習一個將高維數據映射到較低維度的隱藏空間，同時盡可能保留數據的關鍵特徵。

自編碼器的工作原理如下：
1. **編碼器**：將輸入數據 \( x \) 映射到一個低維的隱含向量 \( z \)。編碼器通常是由多層神經網絡組成，並學習一個壓縮表示 \( z = f(x) \)，其中 \( f \) 是編碼器的參數。
2. **解碼器**：將隱含向量 \( z \) 重建回原始數據 \( \hat{x} \)。解碼器也由多層神經網絡組成，並學習一個重建函數 \( \hat{x} = g(z) \)，其中 \( g \) 是解碼器的參數。

自編碼器的目標是最小化重建誤差，通常使用均方誤差（MSE）或交叉熵損失來衡量原始數據 \( x \) 和重建數據 \( \hat{x} \) 之間的差異：
\[
\mathcal{L}_{\text{reconstruction}} = \| x - \hat{x} \|^2
\]

自編碼器的訓練過程是無監督的，並且不需要標註數據。它僅依賴於數據本身的結構來學習數據的有效表示。

##### 5.1.1 自編碼器的結構

自編碼器的結構由兩個主要部分構成：
1. **編碼器**：將輸入數據映射到隱含空間。通常，編碼器由多層神經網絡組成，並學習如何提取數據的低維特徵。
2. **解碼器**：將隱含空間的表示重建回原始數據。解碼器也由神經網絡組成，並學習如何根據隱含向量生成數據。

編碼器和解碼器的結構可以根據具體任務進行調整。例如，在圖像數據中，編碼器可能包含卷積層（CNN），而解碼器則可能包含反卷積層（Deconvolution）。

##### 5.1.2 自編碼器的類型

除了基本的自編碼器外，還有一些變體被提出來以解決不同的問題。以下是一些常見的自編碼器變體：

1. **去噪自編碼器（Denoising Autoencoder, DAE）**：這種自編碼器在訓練時將輸入數據添加噪聲，並要求模型從噪聲數據中恢復原始數據。這有助於學習更有魯棒性的特徵表示。
   
2. **稀疏自編碼器（Sparse Autoencoder）**：這種自編碼器對隱藏層中的單元施加稀疏性約束，從而強迫編碼器學習到更加稀疏的表示。這在特徵選擇和維度縮減中很有用。

3. **變分自編碼器（VAE）**：VAE是自編碼器的一種擴展，通過將隱含空間建模為概率分佈來引入隨機性，並使用變分推斷進行訓練。

自編碼器的主要優勢是能夠學習數據的低維表示，這對於後續的數據分析、降維、特徵提取等任務非常有用。自編碼器可以應用於圖像壓縮、異常檢測、生成模型等領域。

##### 小結

自編碼器（AE）是一種強大的無監督學習工具，旨在學習數據的低維隱藏表示。它包含編碼器和解碼器兩個部分，並通過最小化重建誤差來進行訓練。自編碼器不僅能進行數據降維，還在許多領域中有廣泛應用。接下來，將介紹變分自編碼器（VAE）如何在自編碼器的基礎上進一步引入隨機性，並改進生成模型的能力。
#### 2.3 傳統機器學習方法

傳統機器學習方法在影像處理和電腦視覺中扮演了重要角色，尤其是在特徵提取後的分類和預測任務中。本節將介紹三種常見的傳統機器學習方法：支持向量機（SVM）、決策樹和隨機森林。

### 2.3.1 支持向量機（SVM）

支持向量機（Support Vector Machine, SVM）是一種監督學習方法，常用於分類和回歸問題。其主要思想是將資料映射到高維空間，並尋找一個最大化間隔的超平面來進行分類。

#### SVM的工作原理：

1. **分類超平面**：SVM的目標是找到一個超平面，使得該超平面能夠將不同類別的資料點分開，並且使得兩類資料點與超平面的間隔最大。
2. **支持向量**：在分類過程中，最接近超平面的資料點稱為支持向量。這些支持向量對於確定超平面的邊界至關重要。
3. **核函數**：當資料無法在原空間中線性分割時，SVM使用核函數將資料映射到更高維度的空間，使其線性可分。常見的核函數有線性核、多項式核和高斯徑向基核（RBF）。
4. **最大間隔原則**：SVM會選擇一條能夠最大化兩個類別之間邊界的分割線（或超平面），從而提高分類的魯棒性。

#### 優點與應用：
- SVM對於高維度數據具有很好的表現，特別是在特徵維度遠大於樣本數量的情況下。
- 適用於二分類問題，但也可以通過一對多或一對一方法處理多分類問題。
- 在影像識別、文本分類和生物信息學等領域有廣泛應用。

### 2.3.2 決策樹

決策樹（Decision Tree）是一種基於樹狀結構的監督學習方法，用於分類和回歸任務。它通過對特徵進行一系列的判斷，從根節點到葉節點的路徑來決定輸出的分類或預測值。

#### 決策樹的工作原理：

1. **選擇最佳分割特徵**：在每個節點，決策樹會選擇一個特徵來對樣本進行分割，這樣可以最大程度地減少樣本的不確定性。常用的分割準則包括基尼指數、信息增益和均方誤差。
2. **遞歸分割**：決策樹從根節點開始，對樣本進行遞歸分割，直到每個葉節點只包含同類樣本或達到某個停止條件（如樹的深度或樣本數量）。
3. **樹的剪枝**：為了防止過擬合，決策樹在建樹後會進行剪枝操作，去掉一些無用的分支，使得模型更簡潔且具備較好的泛化能力。

#### 優點與應用：
- 決策樹易於理解，並且具有很好的可解釋性。每個分割規則都可以直觀地表示為一個判斷條件。
- 適用於分類和回歸任務，並且可以處理數值型和類別型特徵。
- 廣泛應用於風險管理、醫學診斷、營銷分析等領域。

### 2.3.3 隨機森林

隨機森林（Random Forest）是一種集成學習方法，通過訓練多棵決策樹來進行預測或分類。每棵樹的訓練數據來自原始數據集的隨機抽樣，並且每棵樹在分裂過程中只使用隨機選擇的特徵，這樣可以減少過擬合並提高模型的泛化能力。

#### 隨機森林的工作原理：

1. **隨機選擇樣本**：隨機森林通過自助抽樣（Bootstrap）方法，從訓練數據集中隨機選取樣本，這樣每棵樹的訓練數據集都是不同的。
2. **隨機選擇特徵**：在每個節點的分裂過程中，隨機森林不會考慮所有特徵，而是隨機選擇一個特徵子集來進行分裂。
3. **集成學習**：隨著多棵樹的訓練和預測，隨機森林通過對所有樹的預測結果進行投票（分類任務）或平均（回歸任務）來得出最終結果。

#### 優點與應用：
- 隨機森林可以有效防止過擬合，並且在高維數據中表現優異。
- 隨機森林能夠處理缺失值並且對噪聲數據具有較強的魯棒性。
- 在影像分類、文本分類、金融風險分析和醫學診斷等領域得到廣泛應用。

### 2.3.4 小結

支持向量機（SVM）、決策樹和隨機森林是三種強大的傳統機器學習方法，各自具有不同的特點和優勢。SVM適合處理高維度數據，並且具有較好的分類性能；決策樹則提供了簡單且可解釋的模型，特別適合於需要解釋和理解模型決策過程的應用；隨機森林則通過集成多棵決策樹，能夠提供穩定且高效的預測結果。這些方法在影像處理、文本分析和生物學等領域的應用中，仍然是非常有價值的工具。
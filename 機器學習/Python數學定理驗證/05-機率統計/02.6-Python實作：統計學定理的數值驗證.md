### 2.6 Python實作：統計學定理的數值驗證

在本節中，我們將使用 Python 實現統計學中的一些基本定理的數值驗證。這些驗證將包括假設檢定、中央極限定理的驗證、回歸分析以及貝葉斯統計方法的應用。我們將用隨機生成的數據來驗證這些統計定理，並通過圖形和數值結果展示它們的有效性。

---

#### 1. 中央極限定理的數值驗證

**中央極限定理**表明，無論原始數據的分佈如何，當樣本數夠大時，樣本均值的分佈會趨近於正態分佈。

假設我們從一個均勻分佈（uniform distribution）中抽取樣本，並不斷增加樣本大小來觀察均值的分佈變化。

```python
import numpy as np
import matplotlib.pyplot as plt

# 設定參數
n_samples = 10000  # 總樣本數
sample_size = [5, 30, 100, 1000]  # 不同樣本大小

# 中央極限定理驗證
plt.figure(figsize=(10, 8))
for i, size in enumerate(sample_size, 1):
    # 抽取樣本並計算每次的均值
    sample_means = [np.mean(np.random.uniform(0, 1, size)) for _ in range(n_samples)]
    
    # 顯示結果
    plt.subplot(2, 2, i)
    plt.hist(sample_means, bins=30, density=True, alpha=0.6, color='g')
    plt.title(f'Sample size = {size}')
    plt.xlabel('Sample Mean')
    plt.ylabel('Density')

plt.tight_layout()
plt.show()
```

在這段程式中，我們從均勻分佈中抽取樣本，並觀察不同樣本大小對樣本均值分佈的影響。隨著樣本數增大，樣本均值的分佈逐漸逼近正態分佈，這證明了中央極限定理。

---

#### 2. 假設檢定：t 檢定的數值驗證

在統計學中，**t 檢定**用於檢查樣本均值是否顯著地偏離假設的均值。這裡我們將驗證 t 檢定，假設我們知道母體均值為 0，並通過樣本來檢測這一假設。

```python
from scipy import stats

# 生成一個隨機樣本
np.random.seed(0)
data = np.random.normal(0, 1, 30)  # 均值為0，標準差為1的正態分佈樣本

# 進行 t 檢定
t_stat, p_value = stats.ttest_1samp(data, 0)

# 顯示結果
print(f"t-statistic: {t_stat:.3f}")
print(f"p-value: {p_value:.3f}")

# 根據p-value進行假設檢定
if p_value < 0.05:
    print("拒絕零假設：樣本均值顯著與0不同")
else:
    print("接受零假設：樣本均值與0無顯著差異")
```

這段程式碼生成了一組來自標準正態分佈的數據，並使用 **t 檢定**來檢查樣本均值是否與假設的均值 0 有顯著差異。最後根據 p 值來決定是否拒絕零假設。

---

#### 3. 回歸分析：線性回歸的數值驗證

在回歸分析中，我們通常會檢查自變量與因變量之間的線性關係。這裡我們將使用線性回歸來檢驗兩個變數之間的關係。

```python
from sklearn.linear_model import LinearRegression

# 生成自變量和因變量
np.random.seed(42)
X = np.random.rand(100, 1)  # 100個隨機自變量
y = 3 * X + np.random.randn(100, 1)  # y = 3X + 噪聲

# 建立並擬合線性回歸模型
model = LinearRegression()
model.fit(X, y)

# 預測並繪製結果
y_pred = model.predict(X)

# 顯示回歸線
plt.scatter(X, y, color='blue', label='Data')
plt.plot(X, y_pred, color='red', label='Regression Line')
plt.title('Linear Regression Example')
plt.xlabel('X')
plt.ylabel('y')
plt.legend()
plt.show()

# 顯示回歸參數
print(f"回歸係數：{model.coef_[0][0]:.3f}")
print(f"截距：{model.intercept_[0]:.3f}")
```

這段程式碼通過隨機生成的數據擬合了一條線性回歸模型，並繪製回歸線。最後，我們顯示回歸模型的係數與截距。

---

#### 4. 最大似然估計的數值驗證

**最大似然估計（MLE）**是一種估計未知參數的方法，通過最大化似然函數來得到最佳參數。在這裡，我們將演示如何使用最大似然估計來估計正態分佈的均值和標準差。

```python
from scipy.optimize import minimize

# 假設生成一組數據
data = np.random.normal(5, 2, 1000)

# 定義對數似然函數（負對數似然，因為minimize函數最小化）
def negative_log_likelihood(params):
    mu, sigma = params[0], params[1]
    return -np.sum(np.log(stats.norm.pdf(data, mu, sigma)))

# 初始參數猜測
initial_guess = [0, 1]

# 最小化負對數似然
result = minimize(negative_log_likelihood, initial_guess, bounds=((None, None), (1e-5, None)))

# 顯示結果
mu_estimated, sigma_estimated = result.x
print(f"估計的均值：{mu_estimated:.3f}")
print(f"估計的標準差：{sigma_estimated:.3f}")
```

在這段程式中，我們使用最大似然估計來估計正態分佈的均值和標準差。首先，定義對數似然函數，然後使用 `minimize` 函數來找到最大似然估計的參數。

---

### 結果分析

- **中央極限定理**的數值驗證展示了當樣本數足夠大時，樣本均值的分佈趨近於正態分佈。
- **t 檢定**的驗證結果表明我們可以使用統計檢定來判斷樣本均值是否顯著不同於假設值。
- **線性回歸**結果顯示了自變量和因變量之間的線性關係，並且擬合模型提供了回歸係數。
- **最大似然估計**通過最小化負對數似然函數來估計模型參數，並提供了合理的參數估計。

這些驗證程序展示了統計學中一些基本定理和方法的應用，並通過 Python 來實現數值驗證，幫助我們更好地理解統計學理論在實際問題中的應用。
### **4.3 回退模型的數學表示**

回退模型（Backoff Model）是一種語言模型的技術，主要用於處理N-gram模型中的資料稀疏問題。回退模型的基本思想是，當某個N-gram的概率無法計算時，模型會回退到低階的N-gram模型，直到找到一個可以計算概率的模型。這種方法有助於在語料庫中缺少某些高階N-gram的情況下，依然能夠生成合理的概率分佈。

回退模型的數學表示基於逐步回退的過程，從高階的N-gram模型開始，當該模型的概率估算不可用時，回退到較低階的N-gram模型，並最終回退到單詞級別的模型。回退模型通常與平滑技術結合使用，以處理N-gram中出現的零頻次問題。

#### **4.3.1 回退模型的基本框架**

回退模型的基本框架可以表示為以下形式：


```math
P(w_t | w_{t-1}, \dots, w_{t-N+1}) = 
\begin{cases} 
P_{\text{backoff}}(w_t | w_{t-1}, \dots, w_{t-N+1}) & \text{if high-order N-gram is seen} \\
\alpha_{N-1} \cdot P(w_t | w_{t-1}, \dots, w_{t-N+2}) & \text{if high-order N-gram is unseen (Back off to (N-1)-gram)} \\
\alpha_{N-2} \cdot P(w_t | w_{t-1}, \dots, w_{t-N+3}) & \text{if (N-1)-gram is unseen (Back off to (N-2)-gram)} \\
\vdots & \vdots \\
P(w_t) & \text{if all higher-order N-grams are unseen (Back off to unigram)}
\end{cases}
```


這裡的  $`P(w_t | w_{t-1}, \dots, w_{t-N+1})`$  是基於高階N-gram的條件概率，當高階N-gram的條件概率不可用時，模型會依次回退到較低階的N-gram模型，直到回退到單詞級別的概率  $`P(w_t)`$ ，這即是回退模型的逐步回退過程。

#### **4.3.2 回退模型的數學推導**

回退模型的推導基於對高階N-gram模型的分解，並且利用回退的過程來估算較低階的條件概率。具體的推導過程如下：

假設我們需要計算一個N-gram的條件概率  $`P(w_t | w_{t-1}, \dots, w_{t-N+1})`$ ，如果該N-gram從未出現過，則該條件概率無法直接估算。在這種情況下，我們可以使用以下的回退規則：


```math
P(w_t | w_{t-1}, \dots, w_{t-N+1}) = \lambda_{N} \cdot P(w_t | w_{t-1}, \dots, w_{t-N+1}) + (1 - \lambda_{N}) \cdot P(w_t | w_{t-1}, \dots, w_{t-N+2})
```


這裡， $`\lambda_{N}`$  是一個平滑參數，用來控制高階N-gram和低階N-gram的權重。這個回退規則的意思是，如果高階N-gram不可用，我們會回退到較低階的N-gram模型，即  $`P(w_t | w_{t-1}, \dots, w_{t-N+2})`$ ，並根據某個平滑參數  $`\lambda_{N}`$  分配權重。這樣的逐步回退過程確保了在某些N-gram的頻次為零時，仍然能夠利用較低階的N-gram來估算概率。

#### **4.3.3 計算回退係數**

回退模型中的回退係數  $`\lambda_{N}`$  用來決定在回退過程中不同階段的權重分配。通常，回退係數是根據訓練語料庫中的N-gram頻次來估算的，並且需要經過訓練來獲得。常見的回退係數估算方法包括：
1. **線性回退**：對每個N-gram，計算該N-gram的頻次，並根據頻次大小來決定回退係數。較高頻次的N-gram會被分配較小的回退係數，這樣較低頻次的N-gram會有較大的權重。
2. **絕對回退**：當一個高階N-gram的頻次為零時，將其完全回退到較低階的N-gram，這樣的回退不會根據頻次進行加權，而是簡單地將高階N-gram的概率設為0，然後回退到低階N-gram。
3. **加權回退**：這種方法會根據N-gram的出現頻次進行加權，對頻次較高的N-gram給予較低的回退係數，這樣保證較常見的N-gram能夠保留較高的權重。

#### **4.3.4 回退模型的優勢與挑戰**

回退模型有多個優點：
- **處理資料稀疏問題**：回退模型能夠有效地解決高階N-gram的資料稀疏問題，並且能夠通過回退到較低階N-gram來平滑模型。
- **簡單易實現**：回退模型的實現相對簡單，主要基於高階N-gram的條件概率進行回退和加權。
- **提高泛化能力**：通過回退到低階N-gram，回退模型能夠提高語言模型的泛化能力，對未見過的N-gram進行合理估算。

然而，回退模型也有其挑戰：
- **計算代價**：回退過程涉及多次計算不同階段的N-gram概率，這會增加模型的計算代價，尤其是在大規模語料庫中。
- **平滑參數的選擇**：回退模型需要選擇合適的平滑參數  $`\lambda_{N}`$ ，不當的平滑參數選擇可能會導致模型過度回退或過度平滑，從而影響模型性能。

#### **4.3.5 小結**

回退模型通過逐步回退到低階N-gram模型來解決高階N-gram模型中出現的資料稀疏問題。它結合了平滑技術與簡單的概率估算方法，對於未出現過的N-gram進行合理的估算。雖然回退模型具有簡單易實現的優勢，但在大規模語料庫中，計算代價和回退參數的選擇仍然是需要考慮的挑戰。
### **A1 - 數學符號表與常用公式**

在這一部分，我們將列出一些在本書中常見的數學符號和公式，這些符號和公式在理解理論基礎和數學推導時非常重要。

#### **常用數學符號**

1. **集合與邏輯符號**
   -  $`A \cup B`$ : 集合  $`A`$  和  $`B`$  的聯集
   -  $`A \cap B`$ : 集合  $`A`$  和  $`B`$  的交集
   -  $`A^C`$ : 集合  $`A`$  的補集
   -  $`\emptyset`$ : 空集
   -  $`\forall`$ : "對所有"（∀）
   -  $`\exists`$ : "存在"（∃）
   -  $`\in`$ : 屬於（例如  $`x \in A`$  表示  $`x`$  屬於集合  $`A`$ ）

2. **向量與矩陣符號**
   -  $`\mathbf{v}`$ : 向量  $`\mathbf{v}`$ 
   -  $`\mathbf{A}`$ : 矩陣  $`\mathbf{A}`$ 
   -  $`\mathbf{A}^{T}`$ : 矩陣  $`\mathbf{A}`$  的轉置
   -  $`\mathbf{A}^{-1}`$ : 矩陣  $`\mathbf{A}`$  的逆矩陣
   -  $`\| \mathbf{v} \|`$ : 向量  $`\mathbf{v}`$  的範數（如  $`\| \mathbf{v} \|_2`$  為  $`L_2`$  範數）
   -  $`\mathbf{I}`$ : 單位矩陣

3. **微積分符號**
   -  $`\frac{d}{dx}`$ : 對變數  $`x`$  求導
   -  $`\frac{\partial}{\partial x}`$ : 偏導數
   -  $`\int`$ : 積分符號
   -  $`\sum`$ : 求和符號
   -  $`\prod`$ : 求積符號
   -  $`\nabla`$ : 梯度運算符（例如， $`\nabla f`$  表示對函數  $`f`$  求梯度）

4. **概率與統計符號**
   -  $`P(A)`$ : 事件  $`A`$  的概率
   -  $`\mathbb{E}[X]`$ : 隨機變數  $`X`$  的期望值
   -  $`\text{Var}(X)`$ : 隨機變數  $`X`$  的方差
   -  $`\mathbb{P}(X = x)`$ : 隨機變數  $`X`$  取值為  $`x`$  的概率
   -  $`\mathbb{N}`$ : 自然數集合
   -  $`\mathbb{R}`$ : 實數集合

5. **線性代數與優化符號**
   -  $`\mathbf{W}`$ : 重量矩陣
   -  $`b`$ : 偏置項
   -  $`\lambda`$ : 正則化參數（例如 L2 正則化中的權重衰減參數）
   -  $`\nabla_{\theta} L(\theta)`$ : 损失函數  $`L`$  相對於參數  $`\theta`$  的梯度

6. **常用數學符號**
   -  $`\mathbb{I}(\cdot)`$ : 指示函數（例如  $`\mathbb{I}(x > 0) = 1`$  if  $`x > 0`$ , otherwise 0）
   -  $`\log(x)`$ : 常用對數（以  $`e`$  為底的對數）
   -  $`\exp(x)`$ : 指數函數
   -  $`\sin(x), \cos(x), \tan(x)`$ : 三角函數

#### **常用公式**

1. **線性代數**
   - 矩陣乘法： $`\mathbf{C} = \mathbf{A} \mathbf{B}`$ 
   - 向量內積： $`\mathbf{v} \cdot \mathbf{w} = \sum_{i=1}^{n} v_i w_i`$ 
   - 向量外積（在  $`\mathbb{R}^3`$  中）： $`\mathbf{v} \times \mathbf{w} = \begin{vmatrix} \mathbf{i} & \mathbf{j} & \mathbf{k} \\ v_1 & v_2 & v_3 \\ w_1 & w_2 & w_3 \end{vmatrix}`$ 

2. **微積分**
   - 鏈式法則： $`\frac{d}{dx} f(g(x)) = f'(g(x)) \cdot g'(x)`$ 
   - 泰勒展開式： $`f(x) \approx f(a) + f'(a)(x - a) + \frac{f''(a)}{2}(x - a)^2 + \dots`$ 
   - 積分的基本定理： $`\int_{a}^{b} f(x) \, dx = F(b) - F(a)`$ 

3. **概率與統計**
   - 條件概率： $`P(A | B) = \frac{P(A \cap B)}{P(B)}`$ 
   - 貝葉斯定理： $`P(A | B) = \frac{P(B | A) P(A)}{P(B)}`$ 
   - 高斯分布的概率密度函數：  
     
```math
f(x | \mu, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left( -\frac{(x - \mu)^2}{2\sigma^2} \right)
```

   - 最大似然估計（MLE）：  
     
```math
\hat{\theta}_{MLE} = \arg \max_{\theta} \prod_{i=1}^{n} p(x_i | \theta)
```


4. **優化算法**
   - 梯度下降：  
     
```math
\theta_{t+1} = \theta_t - \eta \nabla_{\theta} L(\theta_t)
```

     其中， $`\eta`$  是學習率， $`L(\theta_t)`$  是損失函數。

5. **神經網絡與深度學習**
   - 激活函數（Sigmoid）：  
     
```math
\sigma(x) = \frac{1}{1 + \exp(-x)}
```

   - ReLU 激活函數：  
     
```math
\text{ReLU}(x) = \max(0, x)
```

   - 反向傳播的梯度：  
     
```math
\frac{\partial L}{\partial w} = \frac{\partial L}{\partial a} \cdot \frac{\partial a}{\partial w}
```


6. **注意力機制**
   - 自注意力：  
     
```math
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{Q K^T}{\sqrt{d_k}}\right) V
```

   - 多頭注意力：  
     
```math
\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \dots, \text{head}_h) W^O
```

     其中， $`h`$  是頭數， $`W^O`$  是輸出的權重矩陣。

---

這些數學符號和公式在本書的各章節中將反覆使用，對於理解各種算法和模型的數學基礎非常有幫助。
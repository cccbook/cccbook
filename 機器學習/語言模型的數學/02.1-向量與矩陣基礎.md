### **第 2 章：線性代數與微積分基礎**

#### **2.1 向量與矩陣基礎**

線性代數是機器學習、數據分析以及許多數學和工程領域的基礎工具。向量和矩陣是線性代數中最基本的概念，它們在數學模型中被廣泛使用，尤其是在描述多維數據、線性變換和系統求解中。理解這些基本概念是理解更多進階主題的基礎。

##### **2.1.1 向量（Vector）**

向量是一種有序的數字集合，通常用於表示多維空間中的位置或方向。數學上，一個向量可以表示為一個有 \( n \) 個分量的數列。假設有一個 \( n \)-維的向量 \( \mathbf{v} \)，它可以表示為：

\[
\mathbf{v} = \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix}
\]

這裡，\( v_1, v_2, \dots, v_n \) 是向量 \( \mathbf{v} \) 的各個分量。向量常用來表示空間中的位置、運動、力量等概念，並且在許多應用中，向量的運算（如加法、標量乘法等）都是基本操作。

**向量的基本運算：**

- **向量加法：** 兩個向量的加法是將對應分量相加。例如，對於兩個向量 \( \mathbf{u} = (u_1, u_2, \dots, u_n) \) 和 \( \mathbf{v} = (v_1, v_2, \dots, v_n) \)，其加法結果為：

\[
\mathbf{u} + \mathbf{v} = (u_1 + v_1, u_2 + v_2, \dots, u_n + v_n)
\]

- **標量乘法：** 向量與標量的乘法是將每個分量與該標量相乘。例如，對於向量 \( \mathbf{v} = (v_1, v_2, \dots, v_n) \) 和標量 \( \alpha \)，其乘法結果為：

\[
\alpha \mathbf{v} = (\alpha v_1, \alpha v_2, \dots, \alpha v_n)
\]

- **向量點積：** 向量的點積（又稱內積）是兩個向量的對應分量相乘並求和的結果。對於向量 \( \mathbf{u} = (u_1, u_2, \dots, u_n) \) 和 \( \mathbf{v} = (v_1, v_2, \dots, v_n) \)，其點積定義為：

\[
\mathbf{u} \cdot \mathbf{v} = u_1 v_1 + u_2 v_2 + \dots + u_n v_n
\]

點積的結果是一個標量，並且可用來計算兩個向量的夾角、向量的正交性等性質。

##### **2.1.2 矩陣（Matrix）**

矩陣是由數字排列成的矩形陣列，可以看作是多個向量的組合。矩陣在解線性方程組、進行線性變換、描述數據集等方面有著重要的應用。

一個 \( m \times n \) 的矩陣 \( \mathbf{A} \) 可以表示為：

\[
\mathbf{A} = \begin{pmatrix} a_{11} & a_{12} & \dots & a_{1n} \\ a_{21} & a_{22} & \dots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{m1} & a_{m2} & \dots & a_{mn} \end{pmatrix}
\]

這裡，矩陣的元素 \( a_{ij} \) 表示位於第 \( i \) 行第 \( j \) 列的元素。矩陣通常用來表示變換規則、系統的係數、數據集等。

**矩陣的基本運算：**

- **矩陣加法：** 兩個形狀相同的矩陣可以進行加法運算，即對應元素相加。例如，對於兩個矩陣 \( \mathbf{A} = \begin{pmatrix} a_{ij} \end{pmatrix} \) 和 \( \mathbf{B} = \begin{pmatrix} b_{ij} \end{pmatrix} \)，其加法結果為：

\[
\mathbf{A} + \mathbf{B} = \begin{pmatrix} a_{11} + b_{11} & a_{12} + b_{12} & \dots \\ a_{21} + b_{21} & a_{22} + b_{22} & \dots \end{pmatrix}
\]

- **矩陣與標量乘法：** 矩陣的每一個元素都與標量相乘。例如，對於矩陣 \( \mathbf{A} = \begin{pmatrix} a_{ij} \end{pmatrix} \) 和標量 \( \alpha \)，其乘法結果為：

\[
\alpha \mathbf{A} = \begin{pmatrix} \alpha a_{11} & \alpha a_{12} & \dots \\ \alpha a_{21} & \alpha a_{22} & \dots \end{pmatrix}
\]

- **矩陣乘法：** 矩陣乘法是將兩個矩陣的對應元素進行運算的過程。對於矩陣 \( \mathbf{A} \) 和 \( \mathbf{B} \)，矩陣乘法定義為：

\[
\mathbf{C} = \mathbf{A} \cdot \mathbf{B}
\]

其中矩陣 \( \mathbf{C} \) 的元素 \( c_{ij} \) 為矩陣 \( \mathbf{A} \) 第 \( i \) 行與矩陣 \( \mathbf{B} \) 第 \( j \) 列的對應元素點積。即：

\[
c_{ij} = \sum_{k=1}^n a_{ik} b_{kj}
\]

矩陣乘法是線性代數中的一個重要運算，廣泛應用於解線性方程組、計算線性變換等。

##### **2.1.3 行列式與逆矩陣**

行列式（determinant）是與矩陣相關的一個數值，它反映了矩陣的某些性質。行列式常用來判定矩陣是否可逆、求解線性方程組等。

- **行列式：** 例如，對於 \( 2 \times 2 \) 矩陣 \( \mathbf{A} = \begin{pmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{pmatrix} \)，其行列式定義為：

\[
\text{det}(\mathbf{A}) = a_{11}a_{22} - a_{12}a_{21}
\]

- **逆矩陣：** 如果矩陣 \( \mathbf{A} \) 的行列式非零，則該矩陣是可逆的。逆矩陣 \( \mathbf{A}^{-1} \) 是滿足：

\[
\mathbf{A} \cdot \mathbf{A}^{-1} = \mathbf{I}
\]

其中 \( \mathbf{I} \) 是單位矩陣。

##### **2.1.4 向量與矩陣的應用**

- **線性變換：** 矩陣可以用來表示線性變換，將一個向量映射到另一個向量。例如，對於向量 \( \mathbf{v} \) 和矩陣 \( \mathbf{A} \)，線性變換可表示為：

\[
\mathbf{v'} = \mathbf{A} \cdot \mathbf{v}
\]

- **數據表示：** 在機器學習和數據科學中，數據常常以矩陣的形式表示，特別是當每個樣本有多個特徵時。矩陣可以有效地表示並處理大量數據。

#### **小結**

向量和矩陣是線性代數中的基礎概念，並在數學建模、機器學習、計算機科學等領域中有廣泛的應用。理解向量和矩陣的基本運算以及它們在解線性方程組和描述線性變換中的作用，是進一步學習數學和科學方法的基礎。
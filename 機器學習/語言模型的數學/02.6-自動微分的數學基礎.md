### **2.6 自動微分的數學基礎**

自動微分（Automatic Differentiation，簡稱 Autograd 或 AD）是一種計算導數的方法，廣泛應用於數值優化、機器學習和深度學習中。自動微分不是數值微分（例如使用差分公式近似求導數）或符號微分（例如手動推導公式），而是一種通過計算機程序自動生成導數的技術。自動微分的主要優勢是它能夠精確計算導數，並且具有高效性。

本章將介紹自動微分的數學基礎，並探討其在機器學習中的應用，特別是在神經網絡訓練中的重要性。

#### **2.6.1 自動微分的基本概念**

自動微分是基於鏈式法則進行的。給定一個由標量變數組成的計算圖（通常是復雜的函數或神經網絡的計算過程），自動微分會利用這些變數之間的依賴關係計算出每個變數對最終輸出的貢獻。

自動微分的基本思想是將一個複雜的計算過程分解為一系列簡單的算術運算，並在每一步中計算導數。

自動微分主要有兩種模式：
1. **正向模式（Forward Mode）**
2. **反向模式（Reverse Mode）**

##### **2.6.1.1 正向模式（Forward Mode）**

在正向模式中，從輸入開始，逐步計算每個變數對輸出的影響。對於一個多變數函數 \( f(\mathbf{x}) = f(x_1, x_2, \dots, x_n) \)，正向模式的目標是計算 \( \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \dots, \frac{\partial f}{\partial x_n} \)，即每個變數對結果的導數。

正向模式的計算過程是：
1. 從每個變數的初始值開始。
2. 使用鏈式法則對每個變數進行微分，計算每個中間變數的導數。
3. 最後，計算函數的輸出對所有變數的導數。

正向模式的計算優勢在於它可以高效地處理小維度輸入（即變數較少的情況），但當輸入變數數量非常大時，它的效率會降低。

##### **2.6.1.2 反向模式（Reverse Mode）**

反向模式的核心思想是：先計算正向傳遞（即計算出函數的輸出），然後根據輸出對所有中間變數進行反向傳遞，計算每個變數的導數。反向模式特別適合用於需要對多個輸入變數求導的情況。

對於一個標量輸出函數 \( f(\mathbf{x}) \)，反向模式的計算過程如下：
1. 計算從輸入到輸出的正向傳遞，記錄每個中間變數。
2. 根據鏈式法則，從輸出向後傳遞，計算每個變數的導數。

反向模式的優勢在於它適用於多輸出或高維度情況，並且能夠在只進行一次前向傳遞的情況下，計算所有變數的導數。這使得反向模式在深度學習中非常有用，因為神經網絡的訓練通常涉及大量的參數和複雜的計算過程。

#### **2.6.2 自動微分的鏈式法則**

自動微分的核心運作原理是鏈式法則。鏈式法則在微積分中表示為：如果一個變數 \( z \) 是變數 \( x \) 和 \( y \) 的函數，即 \( z = f(x, y) \)，而 \( x \) 和 \( y \) 又是其他變數的函數，那麼變數 \( z \) 對這些變數的導數可以表示為：

\[
\frac{dz}{d\mathbf{u}} = \frac{\partial z}{\partial x} \frac{\partial x}{\partial u} + \frac{\partial z}{\partial y} \frac{\partial y}{\partial u}
\]

在自動微分中，這個過程會被反覆使用，直到最終計算出所有變數的導數。

##### **2.6.2.1 正向模式中的鏈式法則**

在正向模式中，對於函數 \( f(x) \) 和 \( g(x) \)，如果我們知道它們的導數 \( f'(x) \) 和 \( g'(x) \)，則可以使用鏈式法則來計算複合函數 \( h(x) = f(g(x)) \) 的導數：

\[
\frac{dh}{dx} = f'(g(x)) \cdot g'(x)
\]

正向模式會計算每一個變數對輸出結果的影響，並在每一步應用鏈式法則。

##### **2.6.2.2 反向模式中的鏈式法則**

反向模式則從結果向後計算，對每一個中間變數的導數進行累積。例如，對於 \( h(x) = f(g(x)) \)，反向模式計算：

\[
\frac{dh}{dx} = f'(g(x)) \cdot g'(x)
\]

不過在反向模式中，我們會反向計算每個變數的導數，並將每一層的影響反向累加。

#### **2.6.3 自動微分的應用**

自動微分在許多領域中都有廣泛的應用，特別是在深度學習和優化算法中。

##### **2.6.3.1 神經網絡訓練**

在深度學習中，神經網絡的訓練過程通常是通過反向傳播（Backpropagation）來更新網絡中的參數。反向傳播的核心就是反向模式的自動微分。網絡中的每個參數（如權重和偏置）對損失函數的導數（即梯度）都需要計算，這一過程依賴於高效的自動微分技術。

##### **2.6.3.2 最優化算法**

在最優化問題中，許多目標函數是複雜的非線性函數，需要計算其梯度以更新參數。自動微分使得這一過程更加高效且準確，特別是在多維參數空間中，幫助優化算法找到最小值。

#### **2.6.4 小結**

自動微分通過將複雜的計算過程拆解為簡單的基本運算並使用鏈式法則來計算導數，實現了高效、準確的微分計算。正向模式和反向模式是兩種主要的自動微分策略，根據問題的不同特徵，選擇適合的模式有助於提高計算效率。在深度學習、優化和其他科學計算中，自動微分的應用已經成為不可或缺的一部分。
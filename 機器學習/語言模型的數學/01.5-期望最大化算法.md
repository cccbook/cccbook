### **1.5 期望最大化算法（Expectation-Maximization, EM）**

期望最大化（Expectation-Maximization，EM）算法是一種迭代式的統計方法，用於估計含有隱藏變數（或稱為潛在變數）的模型參數。EM算法通常用於處理那些數據中有缺失或無法直接觀察的情況，並在許多機器學習與統計模型中得到了廣泛應用，特別是在高斯混合模型（Gaussian Mixture Models, GMM）等模型的參數估計中。

#### **1.5.1 EM算法的基本思想**

假設我們有一組觀察數據 \( X = \{ x_1, x_2, \dots, x_n \} \)，並且數據的生成過程中包含一組隱藏變數 \( Z = \{ z_1, z_2, \dots, z_n \} \)，我們的目標是估計模型的參數 \( \theta \)，但因為隱藏變數 \( Z \) 是不可觀察的，因此無法直接進行最大似然估計。

EM算法通過將似然估計問題分為兩個步驟來解決這一問題：

1. **E步驟（Expectation step）**：計算隱藏變數 \( Z \) 的條件期望，根據當前的參數估計 \( \hat{\theta}^{(t)} \)，計算隱藏變數 \( Z \) 的後驗分佈。
2. **M步驟（Maximization step）**：根據E步驟計算出的隱藏變數的期望，最大化條件期望來更新模型參數 \( \theta \)。

EM算法的基本思想是迭代進行E步驟和M步驟，直到參數估計收斂為止。

#### **1.5.2 EM算法的具體步驟**

假設數據集的似然函數為 \( L(\theta) \)，其中 \( \theta \) 是我們要估計的模型參數，而 \( Z \) 是隱藏變數。由於隱藏變數是不可觀察的，我們通常無法直接最大化 \( L(\theta) \)。因此，我們將似然函數的問題轉換為對完全數據的對數似然函數進行最大化，並用期望來處理隱藏變數的影響。

具體來說，EM算法通過最大化**對數完全似然函數**（log-likelihood）來進行參數估計。對數似然函數可以分解為：

\[
\log p(X, Z | \theta) = \log p(X | \theta) + \log p(Z | \theta)
\]

我們的目標是最大化 \( \log p(X | \theta) \)，即對觀察數據的對數似然函數進行最大化。由於我們無法直接觀察 \( Z \)，EM算法的關鍵是通過迭代估計隱藏變數 \( Z \) 的期望。

#### **1.5.3 期望步驟（E步驟）**

在E步驟中，我們根據當前參數 \( \hat{\theta}^{(t)} \) 的估計，計算隱藏變數 \( Z \) 的條件期望。具體地，計算隱藏變數 \( Z \) 的後驗分佈 \( p(Z | X, \hat{\theta}^{(t)}) \)，並用這個分佈來更新期望。

通常，E步驟的目標是計算期望對數似然函數：

\[
Q(\theta | \theta^{(t)}) = \mathbb{E}_{Z | X, \theta^{(t)}}[\log p(X, Z | \theta)]
\]

這裡 \( \mathbb{E}_{Z | X, \theta^{(t)}}[\cdot] \) 表示對隱藏變數 \( Z \) 進行條件期望的操作。

#### **1.5.4 最大化步驟（M步驟）**

在M步驟中，我們通過最大化E步驟中得到的期望對數似然函數來更新參數 \( \theta \)。具體地，我們通過求解：

\[
\hat{\theta}^{(t+1)} = \arg\max_{\theta} Q(\theta | \hat{\theta}^{(t)})
\]

來獲得新的參數估計。

#### **1.5.5 EM算法的收斂性**

EM算法是基於對數似然函數的期望最大化原理。每次執行E步驟和M步驟都會提高對數似然函數的值，因此算法具有單調收斂性，即每次迭代後，似然函數的值都不會降低。然而，EM算法可能會收斂到局部最優解，而非全局最優解，這取決於初始參數的選擇。

#### **1.5.6 EM算法的應用**

EM算法在許多實際問題中都得到了應用，特別是在數據中存在缺失或隱藏變數的情況下。以下是一些常見的應用：

1. **高斯混合模型（Gaussian Mixture Models, GMM）**：高斯混合模型是一種常見的生成模型，假設數據來自多個高斯分佈的混合。隱藏變數通常表示每個觀察數據點所屬的高斯分佈。EM算法可以用來估計高斯混合模型中的均值、方差和混合權重等參數。

2. **隱馬爾可夫模型（Hidden Markov Models, HMM）**：隱馬爾可夫模型是一種處理時間序列數據的生成模型，假設觀察序列是由隱藏狀態的序列生成的。EM算法可用來估計HMM中的轉移概率、發射概率等參數。

3. **缺失數據的處理**：當觀察數據中存在缺失值時，EM算法可以用來估計缺失數據，並在此基礎上進行參數估計。

4. **聚類分析**：在聚類分析中，EM算法可用於估計每個數據點的類別分配，特別是在高斯混合模型的框架下。

#### **1.5.7 小結**

期望最大化算法是一種處理隱藏變數或缺失數據的強大工具，通過迭代地進行期望步驟和最大化步驟來估計模型的參數。EM算法在許多領域中都有廣泛應用，尤其是在高斯混合模型、隱馬爾可夫模型和缺失數據處理等方面。儘管EM算法具有收斂性，但它的收斂速度和結果可能會受到初始參數選擇的影響，因此選擇合適的初始化方法對算法的成功至關重要。
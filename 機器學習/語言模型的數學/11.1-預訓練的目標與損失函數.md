### **第 11 章：預訓練與微調**

#### **11.1 預訓練的目標與損失函數**

在現代深度學習中，預訓練（Pre-training）是一種常用的訓練策略，特別是在處理大規模語言模型、圖像模型或多模態模型時。預訓練指的是在特定任務上進行初步訓練，學習通用的表示，再將這些表示應用於具體的下游任務中。預訓練的核心目標是讓模型學會從大量未標註的數據中學習有用的特徵和結構，從而提高在下游任務中的表現。

預訓練的過程中，模型學習到的是一些基礎的知識，例如語言結構、圖像特徵或跨模態的聯繫。預訓練通常依賴自監督學習方法，這意味著模型在訓練過程中並不需要人工標註的數據，而是根據數據本身的結構來生成學習目標。

#### **11.1.1 預訓練的目標**

預訓練的目標是學習通用的表示（representation），這些表示能夠有效地概括數據中的重要結構和信息。在不同的領域，預訓練的目標會有所不同，但其核心思想始終是讓模型學會如何在缺乏明確標註的情況下從大量數據中提取有價值的信息。

- **語言建模**：在自然語言處理（NLP）中，預訓練通常使用自監督學習方法，例如預測單詞或句子的一部分。語言模型的預訓練目標是學會如何建模語言結構，理解單詞之間的關聯，並能夠生成連貫的文本。

- **圖像預訓練**：在計算機視覺中，預訓練可以通過對大量未標註圖像的自監督學習，讓模型學會提取通用的圖像特徵。例如，通過隱式地學習圖像的上下文信息或預測圖像中的遮擋區域，模型可以學習到豐富的圖像表示。

- **多模態學習**：在多模態模型中，預訓練的目標是學習不同模態（如文本、圖像、語音等）之間的聯繫。例如，給定一張圖片，模型可以學習生成描述該圖片的語言，從而學會如何在不同模態間進行轉換。

#### **11.1.2 預訓練的損失函數**

預訓練的損失函數設計對模型的學習目標至關重要。損失函數定義了預訓練過程中模型的學習方向，即如何衡量模型的預測與實際目標之間的差距。根據不同的預訓練目標，損失函數可以有多種不同的形式。

- **自監督學習中的損失函數**：在自監督學習中，預訓練模型的損失函數通常設計為模型預測某些隱藏信息的能力。常見的損失函數包括：
  - **交叉熵損失（Cross-Entropy Loss）**：在語言建模或分類任務中，交叉熵損失通常用來衡量模型預測的機率分佈與實際標註的分佈之間的差異。例如，對於語言模型，模型需要預測當前單詞的條件概率，交叉熵損失衡量了預測單詞分佈與真實分佈之間的差異。
    \[
    L_{\text{CE}} = - \sum_{i=1}^{N} y_i \log(p(y_i))
    \]
    其中，\( y_i \) 是真實標籤，\( p(y_i) \) 是模型預測的機率。

  - **均方誤差損失（Mean Squared Error, MSE）**：在某些回歸問題中，均方誤差損失函數可用於衡量模型預測值與真實值之間的差距。這種損失函數主要用於數值預測任務。
    \[
    L_{\text{MSE}} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y_i})^2
    \]
    其中，\( \hat{y_i} \) 是模型的預測值，\( y_i \) 是真實值。

  - **對比損失（Contrastive Loss）**：對比損失是一種用於學習相似性結構的損失函數，通常應用於嵌入學習中。在預訓練過程中，這種損失函數鼓勵模型將相似的數據點拉近，將不相似的數據點推遠。

- **生成對抗網絡中的損失函數**：在生成對抗網絡（GAN）中，預訓練的損失函數通常由生成器和判別器的損失組成。生成器的目標是生成與真實數據無區別的數據，而判別器的目標則是區分真實數據與生成數據。生成對抗網絡使用對抗損失（Adversarial Loss）來實現這一目標。

  - 生成器損失：讓生成的數據盡可能真實。
    \[
    L_{\text{gen}} = -\log(D(G(z)))
    \]
    其中，\( D \) 是判別器，\( G \) 是生成器，\( z \) 是噪音向量。

  - 判別器損失：讓判別器能夠區分真實與生成的數據。
    \[
    L_{\text{disc}} = - \left[ \log(D(x)) + \log(1 - D(G(z))) \right]
    \]
    其中，\( x \) 是真實數據，\( G(z) \) 是生成數據。

#### **11.1.3 預訓練與微調**

預訓練與微調（Fine-tuning）是深度學習中常見的兩階段訓練方法。在預訓練階段，模型學習通用的表示，而在微調階段，模型會在特定任務上進行調整，進一步優化其性能。這樣的兩階段過程能夠充分發揮預訓練模型的潛力，使其在下游任務中表現出色。

- **預訓練階段**：在預訓練階段，模型學習的是來自大規模數據集的通用知識。在語言模型中，這一階段可以是基於大規模語料的自監督學習，目標是最大化預測語言結構的能力。

- **微調階段**：在微調階段，模型在特定的下游任務（如情感分類、機器翻譯等）上進行訓練。微調時，模型會利用預訓練得到的知識作為初始化，並根據特定任務的標註數據進行優化。這通常需要較少的數據和較少的訓練時間，並能達到較高的性能。

#### **結論**

預訓練的目標是學習通用的數據表示，並通過損失函數來指導模型學習有價值的特徵。預訓練不僅能夠提高模型在下游任務中的性能，還能減少對標註數據的依賴。在實際應用中，預訓練和微調通常結合使用，以最大化深度學習模型的效能和泛化能力。